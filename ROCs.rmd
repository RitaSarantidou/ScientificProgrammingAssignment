ROC curves and AUC
```{r}
set.seed(6)
# Calculate the probability of new observations belonging to each class
# prediction_for_roc_curve will be a matrix with dimensions data_set_size x number_of_classes
prediction_for_roc_curve <- predict(rf,testset[,-371],type="prob")
# Use pretty colours:
pretty_colours <- c("#F8766D","#00BA38","#619CFF")
# Specify the different classes 
classes <- levels(testset$condition)
# For each class
for (i in 1:3)
{
 # Define which observations belong to class[i]
 true_values <- ifelse(testset[,371]==classes[i],1,0)
 # Assess the performance of classifier for class[i]
 pred <- prediction(prediction_for_roc_curve[,i],true_values)
 perf <- performance(pred, "tpr", "fpr")
 if (i==1)
 {
     plot(perf,main="ROC Curve RF ROSE",col=pretty_colours[i]) 
 }
 else
 {
     plot(perf,main="ROC Curve RF ROSE",col=pretty_colours[i],add=TRUE) 
 }

 # Calculate the AUC and print it to screen
 auc.perf <- performance(pred, measure = "auc")
 print(auc.perf@y.values)
}
 legend(0.6, 0.4, legend=classes,
       col=pretty_colours, lty=1:2, cex=0.8)
```


```{r}
set.seed(66)
# Calculate the probability of new observations belonging to each class
# prediction_for_roc_curve will be a matrix with dimensions data_set_size x number_of_classes
prediction_for_roc_curve <- predict(rf_under,testset[,-371],type="prob")
# Use pretty colours:
pretty_colours <- c("#F8766D","#00BA38","#619CFF")
# Specify the different classes 
classes <- levels(testset$condition)
# For each class
for (i in 1:3)
{
 # Define which observations belong to class[i]
 true_values <- ifelse(testset[,371]==classes[i],1,0)
 # Assess the performance of classifier for class[i]
 pred <- prediction(prediction_for_roc_curve[,i],true_values)
 perf <- performance(pred, "tpr", "fpr")
 if (i==1)
 {
     plot(perf,main="ROC Curve RF undersampled",col=pretty_colours[i]) 
 }
 else
 {
     plot(perf,main="ROC Curve RF undersampled",col=pretty_colours[i],add=TRUE) 
 }

 # Calculate the AUC and print it to screen
 auc.perf <- performance(pred, measure = "auc")
 print(auc.perf@y.values)
}
 legend(0.6, 0.4, legend=classes,
       col=pretty_colours, lty=1:2, cex=0.8)
```

ROC curves and AUC for ADASYN data
```{r}
set.seed(10)
# Calculate the probability of new observations belonging to each class
# prediction_for_roc_curve will be a matrix with dimensions data_set_size x number_of_classes
prediction_for_roc_ada <- predict(rf_ada,testset[,-371],type="prob")
# Use pretty colours:
pretty_colours <- c("#F8766D","#00BA38","#619CFF")

# Specify the different classes 
classes <- levels(testset$condition)

# For each class
for (i in 1:3)
{
 # Define which observations belong to class[i]
 true_values <- ifelse(testset[,371]==classes[i],1,0)
 # Assess the performance of classifier for class[i]
 pred <- prediction(prediction_for_roc_ada[,i],true_values)
 perf <- performance(pred, "tpr", "fpr")
 if (i==1)
 {
     plot(perf,main="ROC Curve RF ADASYN",col=pretty_colours[i]) 
 }
 else
 {
     plot(perf,main="ROC Curve RF ADASYN",col=pretty_colours[i],add=TRUE) 
 }

 # Calculate the AUC and print it to screen
 auc.perf <- performance(pred, measure = "auc")
 print(auc.perf@y.values)
}
 legend(0.6, 0.4, legend=classes,
       col=pretty_colours, lty=1:2, cex=0.8)

```
